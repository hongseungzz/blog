---
title: "July 6, 2022, Day15"
../images/Day12_20220701_ML/../images/Day14_20220705_ML/output: 
  html_document:
    toc: true
    toc_float: true
    keep_md: true
date: '2022-07-06 09:22:22'
---


# 데이터 분석(머신러닝, 딥러닝) 프로세스
- 데이터 불러오기
  + csv, 오라클, MySQL, PostgreSQL, 클라우드 DB 연동
- 탐색적 자료 분석
  + 데이터 전처리 및 가공
- 잠정적인 컬럼의 갯수 지정
- 머신러닝 모델(=통계 모델링, t.test, 분산분석, 교차분석)
- 머신러닝 모델의 경우 배포 (현재는 X)
  + JSP 스프링 웹개발 시, 배울 예정
- 통계 모델링의 경우, p-value 값 기준으로, 귀무가설 및 대립가설 검정

- 공통 : 결과 보고서 작성
  + PPT 만들어야 함
  + 중요도 50:50

# 그래프 복습
- 수치형 데이터 시각화
- 범주형 데이터 시각화
- 데이터 관계 시각화
- matplotlib 라이브러리 방법 (복잡)
- seaborn 라이브러리 방법 (단순)
  + 복잡한 그래프를 그리려 할 때 --> matplotlib
  + 1줄 그래프 --> seaborn

### 수치형 데이터 시각화



```python
import seaborn as sns
titanic = sns.load_dataset('titanic')
titanic.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 891 entries, 0 to 890
    Data columns (total 15 columns):
     #   Column       Non-Null Count  Dtype   
    ---  ------       --------------  -----   
     0   survived     891 non-null    int64   
     1   pclass       891 non-null    int64   
     2   sex          891 non-null    object  
     3   age          714 non-null    float64 
     4   sibsp        891 non-null    int64   
     5   parch        891 non-null    int64   
     6   fare         891 non-null    float64 
     7   embarked     889 non-null    object  
     8   class        891 non-null    category
     9   who          891 non-null    object  
     10  adult_male   891 non-null    bool    
     11  deck         203 non-null    category
     12  embark_town  889 non-null    object  
     13  alive        891 non-null    object  
     14  alone        891 non-null    bool    
    dtypes: bool(2), category(2), float64(2), int64(4), object(5)
    memory usage: 80.7+ KB
    


```python
# 히스토그램
sns.histplot(data = titanic, x = 'age', bins = 10, hue = 'alive', multiple = 'stack')
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7f5e000bbdd0>




    
![png](output_4_1.png)
    


- 위 그래프를 보아하니 블라블라...


```python
# 커널밀도추정 함수 그래프
# 연속형 데이터 1개만 쓸 때 사용
sns.kdeplot(data = titanic, x = 'age', hue = 'alive', multiple = 'stack')
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7f5dffd36650>




    
![png](output_6_1.png)
    


#### 분포도
- 수치형 데이터 한 개 컬럼의 분포를 나타내는 그래프
- 정규분포인가?
  + 평균을 0으로 잡음


```python
sns.displot(data = titanic, x = 'age')
```




    <seaborn.axisgrid.FacetGrid at 0x7f5dffcfce50>




    
![png](output_8_1.png)
    



```python
sns.displot(data = titanic, x = 'age', kde = True)
```




    <seaborn.axisgrid.FacetGrid at 0x7f5dffd64250>




    
![png](output_9_1.png)
    


## 범주형 데이터 시각화
- 주 : x축 범주형, y축 수치 데이터
- x축 범주형, y축 범주형
  + 히트맵



```python
# 막대 그래프
sns.barplot(x = 'class', y = 'fare', data = titanic)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7f5dffb84bd0>




    
![png](output_11_1.png)
    


- 에러 바(오차막대) : 샘플링에서 나타나는 오차를 시각적으로 표시


```python
# 포인트 플롯
sns.pointplot(x = 'class', y = 'fare', data = titanic)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7f5dffad6a90>




    
![png](output_13_1.png)
    


- 박스플롯
  + 제1사분위 : 전체 데이터 중 하위 25%
  + 사분위 범위 수(IQR) : 제3사분위 - 제1사분위
  + 최댓값 : 제3사분위 + (1.5 * 10)
  + 최댓값 바깥의 데이터 : 이상치


```python
# boxplot
sns.boxplot(x = 'class', y = 'age', data = titanic)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7f5dffab6dd0>




    
![png](output_15_1.png)
    



```python
# 바이올린플롯
sns.violinplot(x = 'class', y = 'age', hue = 'sex', data = titanic, split = True)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7f5dff9df5d0>




    
![png](output_16_1.png)
    


#### 카운트 플롯
- 범주형 데이터의 빈도 수를 시각화


```python
sns.countplot(x = 'alive', data = titanic)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7f5dff96a050>




    
![png](output_18_1.png)
    


## 데이터 관계 시각화
- 여러 데이터 사이의 관계도를 파악하기 위한 그래프



```python
import pandas as pd

df = pd.DataFrame({'foo': ['one', 'one', 'one', 'two', 'two',
                           'two'],
                   'bar': ['A', 'B', 'C', 'A', 'B', 'C'],
                   'baz': [1, 2, 3, 4, 5, 6],
                   'zoo': ['x', 'y', 'z', 'q', 'w', 't']})
df

df.pivot(index = ['foo','zoo'], columns = 'bar', values = 'baz')
```





  <div id="df-a05f1ca0-6a27-453f-9709-d4f2ad9d70df">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bar</th>
      <th>A</th>
      <th>B</th>
      <th>C</th>
    </tr>
    <tr>
      <th>foo</th>
      <th>zoo</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="3" valign="top">one</th>
      <th>x</th>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>y</th>
      <td>NaN</td>
      <td>2.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>z</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th rowspan="3" valign="top">two</th>
      <th>q</th>
      <td>4.0</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>t</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>6.0</td>
    </tr>
    <tr>
      <th>w</th>
      <td>NaN</td>
      <td>5.0</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-a05f1ca0-6a27-453f-9709-d4f2ad9d70df')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-a05f1ca0-6a27-453f-9709-d4f2ad9d70df button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-a05f1ca0-6a27-453f-9709-d4f2ad9d70df');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>





```python
flights = sns.load_dataset('flights')
flights.head()
```





  <div id="df-dab4c973-2840-4add-8bb7-644f6fc556db">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>year</th>
      <th>month</th>
      <th>passengers</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1949</td>
      <td>Jan</td>
      <td>112</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1949</td>
      <td>Feb</td>
      <td>118</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1949</td>
      <td>Mar</td>
      <td>132</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1949</td>
      <td>Apr</td>
      <td>129</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1949</td>
      <td>May</td>
      <td>121</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-dab4c973-2840-4add-8bb7-644f6fc556db')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-dab4c973-2840-4add-8bb7-644f6fc556db button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-dab4c973-2840-4add-8bb7-644f6fc556db');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>




- 각 연도별, 월별 승객수 구하기


```python
flights['year'].value_counts()
```




    1949    12
    1950    12
    1951    12
    1952    12
    1953    12
    1954    12
    1955    12
    1956    12
    1957    12
    1958    12
    1959    12
    1960    12
    Name: year, dtype: int64




```python
flights_pivot = flights.pivot(index = 'month', columns = 'year', values = 'passengers')
flights_pivot
```





  <div id="df-6c3e1395-c633-4f38-9034-145f23ef577b">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>year</th>
      <th>1949</th>
      <th>1950</th>
      <th>1951</th>
      <th>1952</th>
      <th>1953</th>
      <th>1954</th>
      <th>1955</th>
      <th>1956</th>
      <th>1957</th>
      <th>1958</th>
      <th>1959</th>
      <th>1960</th>
    </tr>
    <tr>
      <th>month</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Jan</th>
      <td>112</td>
      <td>115</td>
      <td>145</td>
      <td>171</td>
      <td>196</td>
      <td>204</td>
      <td>242</td>
      <td>284</td>
      <td>315</td>
      <td>340</td>
      <td>360</td>
      <td>417</td>
    </tr>
    <tr>
      <th>Feb</th>
      <td>118</td>
      <td>126</td>
      <td>150</td>
      <td>180</td>
      <td>196</td>
      <td>188</td>
      <td>233</td>
      <td>277</td>
      <td>301</td>
      <td>318</td>
      <td>342</td>
      <td>391</td>
    </tr>
    <tr>
      <th>Mar</th>
      <td>132</td>
      <td>141</td>
      <td>178</td>
      <td>193</td>
      <td>236</td>
      <td>235</td>
      <td>267</td>
      <td>317</td>
      <td>356</td>
      <td>362</td>
      <td>406</td>
      <td>419</td>
    </tr>
    <tr>
      <th>Apr</th>
      <td>129</td>
      <td>135</td>
      <td>163</td>
      <td>181</td>
      <td>235</td>
      <td>227</td>
      <td>269</td>
      <td>313</td>
      <td>348</td>
      <td>348</td>
      <td>396</td>
      <td>461</td>
    </tr>
    <tr>
      <th>May</th>
      <td>121</td>
      <td>125</td>
      <td>172</td>
      <td>183</td>
      <td>229</td>
      <td>234</td>
      <td>270</td>
      <td>318</td>
      <td>355</td>
      <td>363</td>
      <td>420</td>
      <td>472</td>
    </tr>
    <tr>
      <th>Jun</th>
      <td>135</td>
      <td>149</td>
      <td>178</td>
      <td>218</td>
      <td>243</td>
      <td>264</td>
      <td>315</td>
      <td>374</td>
      <td>422</td>
      <td>435</td>
      <td>472</td>
      <td>535</td>
    </tr>
    <tr>
      <th>Jul</th>
      <td>148</td>
      <td>170</td>
      <td>199</td>
      <td>230</td>
      <td>264</td>
      <td>302</td>
      <td>364</td>
      <td>413</td>
      <td>465</td>
      <td>491</td>
      <td>548</td>
      <td>622</td>
    </tr>
    <tr>
      <th>Aug</th>
      <td>148</td>
      <td>170</td>
      <td>199</td>
      <td>242</td>
      <td>272</td>
      <td>293</td>
      <td>347</td>
      <td>405</td>
      <td>467</td>
      <td>505</td>
      <td>559</td>
      <td>606</td>
    </tr>
    <tr>
      <th>Sep</th>
      <td>136</td>
      <td>158</td>
      <td>184</td>
      <td>209</td>
      <td>237</td>
      <td>259</td>
      <td>312</td>
      <td>355</td>
      <td>404</td>
      <td>404</td>
      <td>463</td>
      <td>508</td>
    </tr>
    <tr>
      <th>Oct</th>
      <td>119</td>
      <td>133</td>
      <td>162</td>
      <td>191</td>
      <td>211</td>
      <td>229</td>
      <td>274</td>
      <td>306</td>
      <td>347</td>
      <td>359</td>
      <td>407</td>
      <td>461</td>
    </tr>
    <tr>
      <th>Nov</th>
      <td>104</td>
      <td>114</td>
      <td>146</td>
      <td>172</td>
      <td>180</td>
      <td>203</td>
      <td>237</td>
      <td>271</td>
      <td>305</td>
      <td>310</td>
      <td>362</td>
      <td>390</td>
    </tr>
    <tr>
      <th>Dec</th>
      <td>118</td>
      <td>140</td>
      <td>166</td>
      <td>194</td>
      <td>201</td>
      <td>229</td>
      <td>278</td>
      <td>306</td>
      <td>336</td>
      <td>337</td>
      <td>405</td>
      <td>432</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-6c3e1395-c633-4f38-9034-145f23ef577b')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-6c3e1395-c633-4f38-9034-145f23ef577b button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-6c3e1395-c633-4f38-9034-145f23ef577b');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>





```python
sns.heatmap(data = flights_pivot)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7f5dff8dc610>




    
![png](output_25_1.png)
    



```python
# 라인플롯
sns.lineplot(x = 'year', y = 'passengers', data = flights) 
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7f5dff81a390>




    
![png](output_26_1.png)
    



```python
# 산점도
tips = sns.load_dataset('tips')
tips.head()
```





  <div id="df-5aa22058-5823-4022-9db0-53643865a165">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>total_bill</th>
      <th>tip</th>
      <th>sex</th>
      <th>smoker</th>
      <th>day</th>
      <th>time</th>
      <th>size</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>16.99</td>
      <td>1.01</td>
      <td>Female</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>10.34</td>
      <td>1.66</td>
      <td>Male</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>3</td>
    </tr>
    <tr>
      <th>2</th>
      <td>21.01</td>
      <td>3.50</td>
      <td>Male</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>3</td>
    </tr>
    <tr>
      <th>3</th>
      <td>23.68</td>
      <td>3.31</td>
      <td>Male</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>24.59</td>
      <td>3.61</td>
      <td>Female</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-5aa22058-5823-4022-9db0-53643865a165')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-5aa22058-5823-4022-9db0-53643865a165 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-5aa22058-5823-4022-9db0-53643865a165');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>




- 두 개의 연속형 데이터


```python
sns.scatterplot(x = 'total_bill', y = 'tip', hue = 'sex', data = tips)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7f5e00581390>




    
![png](output_29_1.png)
    



```python
# 회귀선
sns.regplot(x = 'total_bill', y = 'tip', data = tips)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7f5dff878f10>




    
![png](output_30_1.png)
    


# 머신러닝 리뷰
- 가장 인기 있는 모델
  + LightGBM, XGBoost


### 선형 회귀
- 선형 회귀식을 찾는 것이 중요
- $y = 3x + 4$에 근사한 데이터 50개 생성



```python
import numpy as np
import pandas as pd

# 시드값 고정
np.random.seed(0)
intercept = 4 # 절편, 상수
slope = 3 # 기울기

# 변동성 주기 위해 노이즈 생성
noise = np.random.randn(50, 1)
x = 5 * np.random.randn(50, 1)   # 0과  사이의 실수값 50개 생성
y = slope * x + intercept + noise

# 데이터 프레임 생성
data = pd.DataFrame(
    { 'X' : x[:, 0], 
      'Y' : y[:, 0]}
)
data
```





  <div id="df-1c98d0f0-684c-4b69-bc49-90c68adb9270">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>X</th>
      <th>Y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-4.477333</td>
      <td>-7.667946</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.934512</td>
      <td>10.203695</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-2.554026</td>
      <td>-2.683339</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-5.903161</td>
      <td>-11.468590</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.140911</td>
      <td>5.444825</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2.141659</td>
      <td>9.447700</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.332586</td>
      <td>5.947847</td>
    </tr>
    <tr>
      <th>7</th>
      <td>1.512359</td>
      <td>8.385721</td>
    </tr>
    <tr>
      <th>8</th>
      <td>-3.171610</td>
      <td>-5.618050</td>
    </tr>
    <tr>
      <th>9</th>
      <td>-1.813706</td>
      <td>-1.030519</td>
    </tr>
    <tr>
      <th>10</th>
      <td>-3.362302</td>
      <td>-5.942863</td>
    </tr>
    <tr>
      <th>11</th>
      <td>-1.797766</td>
      <td>0.060976</td>
    </tr>
    <tr>
      <th>12</th>
      <td>-4.065731</td>
      <td>-7.436157</td>
    </tr>
    <tr>
      <th>13</th>
      <td>-8.631413</td>
      <td>-21.772564</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.887131</td>
      <td>7.105255</td>
    </tr>
    <tr>
      <th>15</th>
      <td>-2.008905</td>
      <td>-1.693040</td>
    </tr>
    <tr>
      <th>16</th>
      <td>-8.150992</td>
      <td>-18.958896</td>
    </tr>
    <tr>
      <th>17</th>
      <td>2.313911</td>
      <td>10.736576</td>
    </tr>
    <tr>
      <th>18</th>
      <td>-4.536492</td>
      <td>-9.296408</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.259727</td>
      <td>3.925085</td>
    </tr>
    <tr>
      <th>20</th>
      <td>3.645453</td>
      <td>12.383369</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0.644915</td>
      <td>6.588362</td>
    </tr>
    <tr>
      <th>22</th>
      <td>5.697003</td>
      <td>21.955446</td>
    </tr>
    <tr>
      <th>23</th>
      <td>-6.174129</td>
      <td>-15.264552</td>
    </tr>
    <tr>
      <th>24</th>
      <td>2.011708</td>
      <td>12.304879</td>
    </tr>
    <tr>
      <th>25</th>
      <td>-3.424050</td>
      <td>-7.726517</td>
    </tr>
    <tr>
      <th>26</th>
      <td>-4.353986</td>
      <td>-9.016199</td>
    </tr>
    <tr>
      <th>27</th>
      <td>-2.894248</td>
      <td>-4.869929</td>
    </tr>
    <tr>
      <th>28</th>
      <td>-1.557763</td>
      <td>0.859491</td>
    </tr>
    <tr>
      <th>29</th>
      <td>0.280827</td>
      <td>6.311839</td>
    </tr>
    <tr>
      <th>30</th>
      <td>-5.825749</td>
      <td>-13.322300</td>
    </tr>
    <tr>
      <th>31</th>
      <td>4.504132</td>
      <td>17.890560</td>
    </tr>
    <tr>
      <th>32</th>
      <td>2.328312</td>
      <td>10.097151</td>
    </tr>
    <tr>
      <th>33</th>
      <td>-7.681218</td>
      <td>-21.024452</td>
    </tr>
    <tr>
      <th>34</th>
      <td>7.441261</td>
      <td>25.975871</td>
    </tr>
    <tr>
      <th>35</th>
      <td>9.479446</td>
      <td>32.594687</td>
    </tr>
    <tr>
      <th>36</th>
      <td>5.893898</td>
      <td>22.911984</td>
    </tr>
    <tr>
      <th>37</th>
      <td>-0.899624</td>
      <td>2.503507</td>
    </tr>
    <tr>
      <th>38</th>
      <td>-5.353763</td>
      <td>-12.448616</td>
    </tr>
    <tr>
      <th>39</th>
      <td>5.272259</td>
      <td>19.514473</td>
    </tr>
    <tr>
      <th>40</th>
      <td>-2.015885</td>
      <td>-3.096207</td>
    </tr>
    <tr>
      <th>41</th>
      <td>6.112225</td>
      <td>20.916658</td>
    </tr>
    <tr>
      <th>42</th>
      <td>1.041375</td>
      <td>5.417854</td>
    </tr>
    <tr>
      <th>43</th>
      <td>4.883195</td>
      <td>20.600361</td>
    </tr>
    <tr>
      <th>44</th>
      <td>1.781832</td>
      <td>8.835844</td>
    </tr>
    <tr>
      <th>45</th>
      <td>3.532866</td>
      <td>14.160523</td>
    </tr>
    <tr>
      <th>46</th>
      <td>0.052500</td>
      <td>2.904705</td>
    </tr>
    <tr>
      <th>47</th>
      <td>8.929352</td>
      <td>31.565548</td>
    </tr>
    <tr>
      <th>48</th>
      <td>0.634560</td>
      <td>4.289784</td>
    </tr>
    <tr>
      <th>49</th>
      <td>2.009947</td>
      <td>9.817100</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-1c98d0f0-684c-4b69-bc49-90c68adb9270')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-1c98d0f0-684c-4b69-bc49-90c68adb9270 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-1c98d0f0-684c-4b69-bc49-90c68adb9270');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>





```python
import matplotlib.pyplot as plt
fig, ax = plt.subplots()
ax.scatter(data['X'], data['Y'])
plt.show()
```


    
![png](output_34_0.png)
    



```python
import seaborn as sns
sns.scatterplot(x = 'X', y = 'Y', data = data)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7f5dff6ae910>




    
![png](output_35_1.png)
    


#### 선형회귀 모형 훈련
- 모형 생성 후, 회귀계수 3과 y절편 4에 근사한 값이 나와야 


```python
from sklearn.linear_model import LinearRegression
lr_model = LinearRegression()
lr_model.fit(x, y)

print("Y절편 : ", lr_model.intercept_)
print("회귀계수 : ", lr_model.coef_)
```

    Y절편 :  [4.13895039]
    회귀계수 :  [[2.98463581]]
    


```python
# 예측값
y_pred = lr_model.predict(x)
fig, ax = plt.subplots()
ax.scatter(x, y)
ax.plot(x, y_pred, color = "green")

# slope, intercept 
label = 'slope: {}\nintercept: {}'.format(round(lr_model.coef_[0][0], 2), round(lr_model.intercept_[0], 2))
ax.text(3.5, 4, label, style ='italic', 
        fontsize = 10, color ="green")
plt.show()
```


    
![png](output_38_0.png)
    


### 로지스틱 회귀


```python
import numpy as np
import matplotlib.pyplot as plt

def sigmoid(arr, scale=1):
    arr = np.asarray(arr)
    result = 1/(1 + np.exp(-arr*scale))
    return result

x = np.linspace(-6, 6)
y = sigmoid(x)

fig, ax = plt.subplots()
ax.plot(x, y)
ax.grid(which='major', axis='y', linestyle='--')
ax.axvline(x=0, color='r', linestyle='--', linewidth=1)
ax.set_ylim(0,1)
ax.set_yticks([0, 1, 0.5])
ax.text(0-0.1, 0.5, '0.5', ha='right')
ax.set_title('Sigmoid Graph')
plt.show()
```


    
![png](output_40_0.png)
    



```python
# 라이브러리 불러오기
import matplotlib.pyplot as plt
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix

# 데이터 가져오기
x = np.arange(10).reshape(-1, 1)
y = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])

# 모델 생성 및 학습
model = LogisticRegression(solver='liblinear', C=10.0, random_state=0)
model.fit(x, y)
```




    LogisticRegression(C=10.0, random_state=0, solver='liblinear')




```python
# 모형 평가
p_pred = model.predict_proba(x)
print("p_pred", p_pred, sep = "\n")
```

    p_pred
    [[0.97979027 0.02020973]
     [0.94958202 0.05041798]
     [0.87976149 0.12023851]
     [0.73975066 0.26024934]
     [0.52477284 0.47522716]
     [0.30020373 0.69979627]
     [0.1428487  0.8571513 ]
     [0.06080627 0.93919373]
     [0.02453462 0.97546538]
     [0.00967652 0.99032348]]
    


```python
y_pred = model.predict(x)
print("y_pred", y_pred)
```

    y_pred [0 0 0 0 0 1 1 1 1 1]
    


```python
fig, ax = plt.subplots()
ax.scatter(x, y)
ax.plot(x, p_pred[:, 1], color = 'black',  marker='o', markersize=6)
ax.plot()

ax.set_xticks(x)
ax.set_yticks(np.arange(0, 1.1, 0.1))

ax.grid(which='major', alpha=0.5)
plt.show()
```


    
![png](output_44_0.png)
    



```python
conf_m = confusion_matrix(y, y_pred)
print(conf_m)
```

    [[5 0]
     [0 5]]
    


```python
cm = confusion_matrix(y, y_pred)

fig, ax = plt.subplots(figsize=(8, 8))
ax.imshow(cm, cmap = 'YlOrRd')
ax.grid(False)
ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0', 'Predicted 1'))
ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0', 'Actual 1'))
ax.set_ylim(1.5, -0.5)
for i in range(2):
    for j in range(2):
        ax.text(j, i, cm[i, j], ha='center', va='center', color='black', fontsize=20)
plt.show()
```


    
![png](output_46_0.png)
    


### 결정 트리

#### 주요 개념
- 작동 원리
  + 데이터를 가장 잘 구분하는 조건을 정함.
  + 조건을 기준으로 데이터를 두 범주로 나눔
  + 나뉜 각 범주의 데이터를 구분하는 조건을 정함
  + 각 조건을 기준으로 데이터를 두 범주로 나눔
  + 언제까지 계속 분할할지 정한 후, 최종 결정 값을 구함.
- 불순도(Impurity)
  + 한 범주 안에 서로 다른 데이터가 얼마나 섞여 있는지 나타냄
  + 흰색과 검은색이 50:50으로 섞여 있다. (불순도 최대)
  + 흰색과 검은색으로 완전 분리 되었다. (불순도 최소)
- 엔트로피(Entropy)
  + 불확실한 정도를 의미함. 0 ~ 1로 정함.
  + 흰색과 검은색이 50:50으로 섞여 있다. 엔트로피 1
  + 흰색과 검은색으로 완전 분리 되었다. 엔트로피 0
- 정보이득(Information Gain)
  + 1에서 엔트로피를 뺀 수치
  + 정보 이득을 최대화하는 방향(엔트로피를 최소화 하는 방향)으로 노드를 분할함
- 지니 불순도(Gini Impurity)
  + 지니 불순도 값이 클수록 불순도도 높고, 작을수록 불순도도 낮음. 엔트로피와 마찬가지로 지니 불순도가 낮아지는 방향으로 노드 분할함.


```python
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split 
import seaborn as sns

titanic = sns.load_dataset('titanic')
titanic.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 891 entries, 0 to 890
    Data columns (total 15 columns):
     #   Column       Non-Null Count  Dtype   
    ---  ------       --------------  -----   
     0   survived     891 non-null    int64   
     1   pclass       891 non-null    int64   
     2   sex          891 non-null    object  
     3   age          714 non-null    float64 
     4   sibsp        891 non-null    int64   
     5   parch        891 non-null    int64   
     6   fare         891 non-null    float64 
     7   embarked     889 non-null    object  
     8   class        891 non-null    category
     9   who          891 non-null    object  
     10  adult_male   891 non-null    bool    
     11  deck         203 non-null    category
     12  embark_town  889 non-null    object  
     13  alive        891 non-null    object  
     14  alone        891 non-null    bool    
    dtypes: bool(2), category(2), float64(2), int64(4), object(5)
    memory usage: 80.7+ KB
    

- survived의 비율을 구함
  + 0 : 사망자
  + 1 : 생존자


```python
titanic['survived'].value_counts()
```




    0    549
    1    342
    Name: survived, dtype: int64




```python
X = titanic[['pclass', 'parch', 'fare']]
y = titanic['survived']

# 훈련데이터, 테스트 데이터 분리
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.3, random_state=42)
X_train.shape, X_test.shape, y_train.shape, y_test.shape
```




    ((623, 3), (268, 3), (623,), (268,))




```python
tree_model = DecisionTreeClassifier()
tree_model.fit(X_train, y_train)

acc = tree_model.score(X_test, y_test)
print(f'모형 정확도 : {acc:.3f}') # 정확도 측정
```

    모형 정확도 : 0.675
    

### 랜덤 포레스트



```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split 
import seaborn as sns 

# tips 데이터셋 
titanic = sns.load_dataset('titanic')

X = titanic[['pclass', 'parch', 'fare']]
y = titanic['survived']

# 훈련데이터, 테스트 데이터 분리
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.3, random_state=42)

# 모델 훈련
rf_model = RandomForestClassifier(random_state=42) # 랜덤 포레스트 정의
rf_model.fit(X_train, y_train)

acc = rf_model.score(X_test, y_test)
print(f'모형 정확도 : {acc:.3f}') # 정확도 측정
```

    모형 정확도 : 0.675
    

## XGBoost & LightGBM (2016 ~ 2017)
- 전통적인 머신러닝 알고리즘의 융합
  + 선형회귀 릿지 라쏘, 과적합 방지 위한 규제
  + 결정 트리의 핵심적인 알고리즘
  + 경사 하강법
  + 부스팅 기법
- 문제점 : 파라미터의 개수가 매우 많음
- 각광 받는 이유
  + 모델 학습 속도
  + 모델의 성능
    + 가장 좋은 모델이란 학습 속도가 빠르면서 성능이 좋은 것 (지금까지 나온 알고리즘과 비교했을 때)
- 개발자 테크트리 : Python 시작
  + JAVA, C, C++
  + C, C++ / R data.table 패키지
- 큰 회사들이 개발
  + 첫 번째 옵션 : 자체적으로 배포하자 --> Python Wrapper API
    + R, 머신러닝 프레임워크 종류多
  + 두 번째 옵션 : Python 프레임워크는 Scikit-Learn으로 통일
    + Python 머신러닝 = Scikit-Learn에서 쉽게 쓸 수 있도록 개발, Scikit-Learn Wrapper API
- ★ 문법적으로 차이가 있다는 것을 확인 ★


### XGBoost Python Wrapper API 방식
- X_train, Y_train
- 각 모듈에 맞도록 행렬을 재변환해야 함


```python
import xgboost as xgb
from sklearn.model_selection import train_test_split
import seaborn as sns

# titanic
titanic = sns.load_dataset('titanic')
titanic.info()

# X -> 독립변수, y -> 종속변수
X = titanic[['pclass', 'parch', 'fare']]
y = titanic['survived']

#훈련데이터, 테스트 데이터 분리
X_train, X_test, Y_train, Y_test = train_test_split(X,
                                                    y,
                                                    stratify = y,
                                                    test_size = 0.3,
                                                    random_state = 42)

X_train.shape, X_test.shape, Y_train.shape, Y_test.shape
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 891 entries, 0 to 890
    Data columns (total 15 columns):
     #   Column       Non-Null Count  Dtype   
    ---  ------       --------------  -----   
     0   survived     891 non-null    int64   
     1   pclass       891 non-null    int64   
     2   sex          891 non-null    object  
     3   age          714 non-null    float64 
     4   sibsp        891 non-null    int64   
     5   parch        891 non-null    int64   
     6   fare         891 non-null    float64 
     7   embarked     889 non-null    object  
     8   class        891 non-null    category
     9   who          891 non-null    object  
     10  adult_male   891 non-null    bool    
     11  deck         203 non-null    category
     12  embark_town  889 non-null    object  
     13  alive        891 non-null    object  
     14  alone        891 non-null    bool    
    dtypes: bool(2), category(2), float64(2), int64(4), object(5)
    memory usage: 80.7+ KB
    




    ((623, 3), (268, 3), (623,), (268,))



- 여기가 핵심


```python
dtrain = xgb.DMatrix(data = X_train, label = y_train)
dtest = xgb.DMatrix(data = X_test, label = y_test)

print(dtrain)
```

    <xgboost.core.DMatrix object at 0x7f5dffde0090>
    

- 머신러닝 코드



```python
# xgb.train
params = {
    'max_depth' : 3,
    'n_estimators' : 100,
    'eta' : 0.1,    # 학습률
    'object' : 'binary:logistic'    # 이진 분류/다중 분류/회귀 중 선택
}
num_rounds = 400

w_list = [(dtrain, 'train'), (dtest,'test')]
xgb_ml = xgb.train(params = params,
                   dtrain = dtrain, 
                   num_boost_round = 400,
                   early_stopping_rounds = 100,
                   evals = w_list)
```

    [0]	train-rmse:0.487915	test-rmse:0.490146
    Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.
    
    Will train until test-rmse hasn't improved in 100 rounds.
    [1]	train-rmse:0.477856	test-rmse:0.482183
    [2]	train-rmse:0.470061	test-rmse:0.47532
    [3]	train-rmse:0.462182	test-rmse:0.470924
    [4]	train-rmse:0.45572	test-rmse:0.466351
    [5]	train-rmse:0.450354	test-rmse:0.462927
    [6]	train-rmse:0.445683	test-rmse:0.459554
    [7]	train-rmse:0.441298	test-rmse:0.458577
    [8]	train-rmse:0.437792	test-rmse:0.456831
    [9]	train-rmse:0.434393	test-rmse:0.456526
    [10]	train-rmse:0.431726	test-rmse:0.455362
    [11]	train-rmse:0.428592	test-rmse:0.454746
    [12]	train-rmse:0.426484	test-rmse:0.454121
    [13]	train-rmse:0.423992	test-rmse:0.453891
    [14]	train-rmse:0.421947	test-rmse:0.453115
    [15]	train-rmse:0.42036	test-rmse:0.452995
    [16]	train-rmse:0.418512	test-rmse:0.452991
    [17]	train-rmse:0.417025	test-rmse:0.452558
    [18]	train-rmse:0.415955	test-rmse:0.45293
    [19]	train-rmse:0.41396	test-rmse:0.453367
    [20]	train-rmse:0.413199	test-rmse:0.453852
    [21]	train-rmse:0.412091	test-rmse:0.453547
    [22]	train-rmse:0.410501	test-rmse:0.4541
    [23]	train-rmse:0.409461	test-rmse:0.453524
    [24]	train-rmse:0.408469	test-rmse:0.453724
    [25]	train-rmse:0.407781	test-rmse:0.454117
    [26]	train-rmse:0.406954	test-rmse:0.454325
    [27]	train-rmse:0.405708	test-rmse:0.454997
    [28]	train-rmse:0.405121	test-rmse:0.455545
    [29]	train-rmse:0.404449	test-rmse:0.455746
    [30]	train-rmse:0.403643	test-rmse:0.45576
    [31]	train-rmse:0.403092	test-rmse:0.456029
    [32]	train-rmse:0.40252	test-rmse:0.456502
    [33]	train-rmse:0.401617	test-rmse:0.456903
    [34]	train-rmse:0.401175	test-rmse:0.457341
    [35]	train-rmse:0.40015	test-rmse:0.458455
    [36]	train-rmse:0.399748	test-rmse:0.458725
    [37]	train-rmse:0.398984	test-rmse:0.45933
    [38]	train-rmse:0.3982	test-rmse:0.459086
    [39]	train-rmse:0.397529	test-rmse:0.459736
    [40]	train-rmse:0.39734	test-rmse:0.460037
    [41]	train-rmse:0.396627	test-rmse:0.460473
    [42]	train-rmse:0.396461	test-rmse:0.460603
    [43]	train-rmse:0.395537	test-rmse:0.460408
    [44]	train-rmse:0.395255	test-rmse:0.460791
    [45]	train-rmse:0.394568	test-rmse:0.461165
    [46]	train-rmse:0.39406	test-rmse:0.461553
    [47]	train-rmse:0.393351	test-rmse:0.461595
    [48]	train-rmse:0.393206	test-rmse:0.461718
    [49]	train-rmse:0.392991	test-rmse:0.462002
    [50]	train-rmse:0.392352	test-rmse:0.461921
    [51]	train-rmse:0.391973	test-rmse:0.462235
    [52]	train-rmse:0.391844	test-rmse:0.462413
    [53]	train-rmse:0.391345	test-rmse:0.462503
    [54]	train-rmse:0.391184	test-rmse:0.462824
    [55]	train-rmse:0.391068	test-rmse:0.462939
    [56]	train-rmse:0.390596	test-rmse:0.462163
    [57]	train-rmse:0.390164	test-rmse:0.462743
    [58]	train-rmse:0.389861	test-rmse:0.463045
    [59]	train-rmse:0.389441	test-rmse:0.462628
    [60]	train-rmse:0.389339	test-rmse:0.462737
    [61]	train-rmse:0.388745	test-rmse:0.462942
    [62]	train-rmse:0.388405	test-rmse:0.462691
    [63]	train-rmse:0.388277	test-rmse:0.463041
    [64]	train-rmse:0.387828	test-rmse:0.463243
    [65]	train-rmse:0.387614	test-rmse:0.463214
    [66]	train-rmse:0.387088	test-rmse:0.463584
    [67]	train-rmse:0.386906	test-rmse:0.463627
    [68]	train-rmse:0.386444	test-rmse:0.463517
    [69]	train-rmse:0.385685	test-rmse:0.463735
    [70]	train-rmse:0.385353	test-rmse:0.463113
    [71]	train-rmse:0.384828	test-rmse:0.463005
    [72]	train-rmse:0.38444	test-rmse:0.462966
    [73]	train-rmse:0.383198	test-rmse:0.462825
    [74]	train-rmse:0.382841	test-rmse:0.462947
    [75]	train-rmse:0.382416	test-rmse:0.463253
    [76]	train-rmse:0.381966	test-rmse:0.462963
    [77]	train-rmse:0.381655	test-rmse:0.463399
    [78]	train-rmse:0.381399	test-rmse:0.463326
    [79]	train-rmse:0.380593	test-rmse:0.463277
    [80]	train-rmse:0.380329	test-rmse:0.463051
    [81]	train-rmse:0.380233	test-rmse:0.46316
    [82]	train-rmse:0.379942	test-rmse:0.463234
    [83]	train-rmse:0.379686	test-rmse:0.463517
    [84]	train-rmse:0.37893	test-rmse:0.463051
    [85]	train-rmse:0.378841	test-rmse:0.463287
    [86]	train-rmse:0.378756	test-rmse:0.463389
    [87]	train-rmse:0.378501	test-rmse:0.463446
    [88]	train-rmse:0.378011	test-rmse:0.463085
    [89]	train-rmse:0.377178	test-rmse:0.46281
    [90]	train-rmse:0.376872	test-rmse:0.462851
    [91]	train-rmse:0.376563	test-rmse:0.46331
    [92]	train-rmse:0.376317	test-rmse:0.463088
    [93]	train-rmse:0.376049	test-rmse:0.463515
    [94]	train-rmse:0.375914	test-rmse:0.463486
    [95]	train-rmse:0.375643	test-rmse:0.463194
    [96]	train-rmse:0.375378	test-rmse:0.463459
    [97]	train-rmse:0.375145	test-rmse:0.46375
    [98]	train-rmse:0.37453	test-rmse:0.463309
    [99]	train-rmse:0.374021	test-rmse:0.463431
    [100]	train-rmse:0.373289	test-rmse:0.463593
    [101]	train-rmse:0.373032	test-rmse:0.463798
    [102]	train-rmse:0.372814	test-rmse:0.464226
    [103]	train-rmse:0.372443	test-rmse:0.464454
    [104]	train-rmse:0.372217	test-rmse:0.464417
    [105]	train-rmse:0.372145	test-rmse:0.464435
    [106]	train-rmse:0.371726	test-rmse:0.464241
    [107]	train-rmse:0.37158	test-rmse:0.464172
    [108]	train-rmse:0.371396	test-rmse:0.464582
    [109]	train-rmse:0.371335	test-rmse:0.4646
    [110]	train-rmse:0.371127	test-rmse:0.464403
    [111]	train-rmse:0.371001	test-rmse:0.464328
    [112]	train-rmse:0.370928	test-rmse:0.464546
    [113]	train-rmse:0.370688	test-rmse:0.464457
    [114]	train-rmse:0.370634	test-rmse:0.464475
    [115]	train-rmse:0.37042	test-rmse:0.464819
    [116]	train-rmse:0.37007	test-rmse:0.46479
    [117]	train-rmse:0.369921	test-rmse:0.464798
    Stopping. Best iteration:
    [17]	train-rmse:0.417025	test-rmse:0.452558
    
    


```python
# 평가
from sklearn.metrics import accuracy_score
pred_probs = xgb_ml.predict(dtest)
y_pred = [1 if x > 0.5 else 0 for x in  pred_probs]

# 예측 라벨과 실제 라벨 사이의 정확도 측정
accuracy_score(y_pred, y_test)
```




    0.6977611940298507



### XGBoost Scikit-Learn API 방식



```python
from sklearn.tree import DecisionTreeClassifier
from xgboost import XGBClassifier     # API

# dt = DecisionTreeClassifier()
xgb_model = XGBClassifier(objective = 'binary:logistic',
                          n_estimators = 100,
                          max_depth = 3,
                          learning_rate = 0.1,
                          num_rounds = 400,
                          random_state = 42)

w_list = [(X_train, y_train), (X_test, y_test)]

xgb_model.fit(X_train, y_train, eval_set = w_list, eval_metric = 'error', verbose = True)

y_probas = xgb_model.predict_proba(X_test)
y_pred = [1 if x > 0.5 else 0 for x in  pred_probs]

# 예측 라벨과 실제 라벨 사이의 정확도 측정
accuracy_score(y_pred, y_test)
```

    [0]	validation_0-error:0.260032	validation_1-error:0.302239
    [1]	validation_0-error:0.260032	validation_1-error:0.302239
    [2]	validation_0-error:0.260032	validation_1-error:0.302239
    [3]	validation_0-error:0.260032	validation_1-error:0.302239
    [4]	validation_0-error:0.260032	validation_1-error:0.302239
    [5]	validation_0-error:0.260032	validation_1-error:0.302239
    [6]	validation_0-error:0.260032	validation_1-error:0.302239
    [7]	validation_0-error:0.260032	validation_1-error:0.302239
    [8]	validation_0-error:0.260032	validation_1-error:0.302239
    [9]	validation_0-error:0.260032	validation_1-error:0.302239
    [10]	validation_0-error:0.260032	validation_1-error:0.302239
    [11]	validation_0-error:0.260032	validation_1-error:0.302239
    [12]	validation_0-error:0.260032	validation_1-error:0.302239
    [13]	validation_0-error:0.247191	validation_1-error:0.298507
    [14]	validation_0-error:0.247191	validation_1-error:0.298507
    [15]	validation_0-error:0.248796	validation_1-error:0.302239
    [16]	validation_0-error:0.248796	validation_1-error:0.302239
    [17]	validation_0-error:0.248796	validation_1-error:0.302239
    [18]	validation_0-error:0.248796	validation_1-error:0.302239
    [19]	validation_0-error:0.248796	validation_1-error:0.302239
    [20]	validation_0-error:0.248796	validation_1-error:0.302239
    [21]	validation_0-error:0.248796	validation_1-error:0.302239
    [22]	validation_0-error:0.248796	validation_1-error:0.302239
    [23]	validation_0-error:0.248796	validation_1-error:0.302239
    [24]	validation_0-error:0.248796	validation_1-error:0.302239
    [25]	validation_0-error:0.248796	validation_1-error:0.302239
    [26]	validation_0-error:0.248796	validation_1-error:0.302239
    [27]	validation_0-error:0.248796	validation_1-error:0.302239
    [28]	validation_0-error:0.247191	validation_1-error:0.302239
    [29]	validation_0-error:0.247191	validation_1-error:0.302239
    [30]	validation_0-error:0.247191	validation_1-error:0.302239
    [31]	validation_0-error:0.243981	validation_1-error:0.298507
    [32]	validation_0-error:0.247191	validation_1-error:0.302239
    [33]	validation_0-error:0.243981	validation_1-error:0.298507
    [34]	validation_0-error:0.243981	validation_1-error:0.298507
    [35]	validation_0-error:0.242376	validation_1-error:0.294776
    [36]	validation_0-error:0.24077	validation_1-error:0.294776
    [37]	validation_0-error:0.24077	validation_1-error:0.294776
    [38]	validation_0-error:0.24077	validation_1-error:0.294776
    [39]	validation_0-error:0.24077	validation_1-error:0.294776
    [40]	validation_0-error:0.24077	validation_1-error:0.294776
    [41]	validation_0-error:0.24077	validation_1-error:0.294776
    [42]	validation_0-error:0.24077	validation_1-error:0.294776
    [43]	validation_0-error:0.24077	validation_1-error:0.294776
    [44]	validation_0-error:0.24077	validation_1-error:0.302239
    [45]	validation_0-error:0.24077	validation_1-error:0.302239
    [46]	validation_0-error:0.24077	validation_1-error:0.302239
    [47]	validation_0-error:0.24077	validation_1-error:0.302239
    [48]	validation_0-error:0.24077	validation_1-error:0.302239
    [49]	validation_0-error:0.24077	validation_1-error:0.302239
    [50]	validation_0-error:0.24077	validation_1-error:0.302239
    [51]	validation_0-error:0.24077	validation_1-error:0.302239
    [52]	validation_0-error:0.23435	validation_1-error:0.302239
    [53]	validation_0-error:0.23435	validation_1-error:0.302239
    [54]	validation_0-error:0.232745	validation_1-error:0.298507
    [55]	validation_0-error:0.229535	validation_1-error:0.298507
    [56]	validation_0-error:0.229535	validation_1-error:0.298507
    [57]	validation_0-error:0.229535	validation_1-error:0.298507
    [58]	validation_0-error:0.229535	validation_1-error:0.298507
    [59]	validation_0-error:0.227929	validation_1-error:0.294776
    [60]	validation_0-error:0.227929	validation_1-error:0.298507
    [61]	validation_0-error:0.227929	validation_1-error:0.298507
    [62]	validation_0-error:0.227929	validation_1-error:0.298507
    [63]	validation_0-error:0.227929	validation_1-error:0.298507
    [64]	validation_0-error:0.227929	validation_1-error:0.298507
    [65]	validation_0-error:0.227929	validation_1-error:0.298507
    [66]	validation_0-error:0.227929	validation_1-error:0.298507
    [67]	validation_0-error:0.227929	validation_1-error:0.298507
    [68]	validation_0-error:0.227929	validation_1-error:0.298507
    [69]	validation_0-error:0.227929	validation_1-error:0.298507
    [70]	validation_0-error:0.227929	validation_1-error:0.298507
    [71]	validation_0-error:0.227929	validation_1-error:0.298507
    [72]	validation_0-error:0.227929	validation_1-error:0.302239
    [73]	validation_0-error:0.227929	validation_1-error:0.302239
    [74]	validation_0-error:0.229535	validation_1-error:0.30597
    [75]	validation_0-error:0.229535	validation_1-error:0.30597
    [76]	validation_0-error:0.229535	validation_1-error:0.30597
    [77]	validation_0-error:0.229535	validation_1-error:0.30597
    [78]	validation_0-error:0.229535	validation_1-error:0.30597
    [79]	validation_0-error:0.229535	validation_1-error:0.30597
    [80]	validation_0-error:0.229535	validation_1-error:0.30597
    [81]	validation_0-error:0.229535	validation_1-error:0.30597
    [82]	validation_0-error:0.229535	validation_1-error:0.30597
    [83]	validation_0-error:0.229535	validation_1-error:0.30597
    [84]	validation_0-error:0.229535	validation_1-error:0.30597
    [85]	validation_0-error:0.229535	validation_1-error:0.30597
    [86]	validation_0-error:0.229535	validation_1-error:0.30597
    [87]	validation_0-error:0.229535	validation_1-error:0.30597
    [88]	validation_0-error:0.229535	validation_1-error:0.30597
    [89]	validation_0-error:0.229535	validation_1-error:0.30597
    [90]	validation_0-error:0.229535	validation_1-error:0.30597
    [91]	validation_0-error:0.229535	validation_1-error:0.30597
    [92]	validation_0-error:0.229535	validation_1-error:0.30597
    [93]	validation_0-error:0.229535	validation_1-error:0.30597
    [94]	validation_0-error:0.227929	validation_1-error:0.313433
    [95]	validation_0-error:0.226324	validation_1-error:0.313433
    [96]	validation_0-error:0.223114	validation_1-error:0.317164
    [97]	validation_0-error:0.223114	validation_1-error:0.317164
    [98]	validation_0-error:0.223114	validation_1-error:0.317164
    [99]	validation_0-error:0.223114	validation_1-error:0.317164
    




    0.6977611940298507



### LightGBM Python Wrapper 방식



```python
# XGBoost 코드와 유사
import lightgbm as lgb 
from sklearn.model_selection import train_test_split 
from sklearn.metrics import accuracy_score
import seaborn as sns 

# tips 데이터셋 
titanic = sns.load_dataset('titanic')

X = titanic[['pclass', 'parch', 'fare']]
y = titanic['survived']

# 훈련데이터, 테스트 데이터 분리
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.3, random_state=42)

# XGBoost 코드와 유사하다. 
dtrain = lgb.Dataset(data = X_train, label = y_train)
dtest = lgb.Dataset(data = X_test, label = y_test)

params = {'max_depth':3,
          'n_estimators':100,
          'learning_rate': 0.1,
          'objective':'binary',
          'metric' : 'binary_error', 
          'num_boost_round' : 400, 
          'verbose' : 1} 

w_list = [dtrain, dtest]
lgb_ml = lgb.train(params=params, train_set = dtrain,\
                  early_stopping_rounds=100, valid_sets= w_list)

pred_probs = lgb_ml.predict(X_test)
y_pred=[1 if x > 0.5 else 0 for x in pred_probs]

# 예측 라벨과 실제 라벨 사이의 정확도 측정
accuracy_score(y_pred, y_test)
```

### LightGBM Scikit-Learn API 방식


```python
from lightgbm import LGBMClassifier
from sklearn.metrics import accuracy_score

# model 
w_list = [dtrain, dtest]
model = LGBMClassifier(objective = 'binary', 
                       metric = 'binary_error',
                       n_estimators=100, 
                       learning_rate=0.1, 
                       max_depth=3, 
                       num_boost_round = 400,
                       random_state = 32)
model.fit(X_train, 
          y_train, 
          eval_set = [(X_train, y_train), (X_test, y_test)], 
          verbose=1,
          early_stopping_rounds = 100)
y_probas = model.predict_proba(X_test) 
y_pred=[1 if x > 0.5 else 0 for x in y_probas[:, 1]] # 예측 라벨(0과 1로 예측)

# 예측 라벨과 실제 라벨 사이의 정확도 측정
accuracy_score(y_pred, y_test)
```
